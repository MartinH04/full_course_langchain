LangChain内置了许多解决方案，以应对在对话中提取和管理信息的挑战。其中一些解决方案非常直观简单，例如我们之前展示的直接将信息放入提示（Prompts）的方法。

然而，我们的解决方案远不止这些。在进行对话的同时，我们还可以使用一种叫做摘要（Summary）的方法。这种方法可以在对话进行的过程中对内容进行概括和整理。另外，我们也可以使用限制窗口的方式，只记忆最近的几轮对话。此外，我们还可以将最近的几次对话进行摘要，对于其他的内容则进行总结。

这种摘要的功能实际上是通过调用语言模型自身来完成的。语言模型会被请求对整个对话进行总结，这也是你将在我们的系统中看到的功能。

除此之外，我们还有一些更高级的解决方案。例如，我们可以制作一种知识图谱记忆，将信息储存在实体记忆中。这样的解决方案可以让我们更高效地管理和使用对话中的信息。

在使用LangChain的各种记忆组件时，我们可能会发现一种现象，那就是当我们多次调用模型进行摘要总结或生成知识图谱时，响应的速度可能会变慢。这是因为这些操作需要模型进行更深入和复杂的信息处理，这在一定程度上增加了处理的时间。

LangChain也支持自定义记忆, 我们尝试做了第一个自定义记忆组件。