# 2.2.2 少样本提示模板

少样本提示模板 (FewShotPromptTemplate)已经被证明是很有用的。通常用户只要输入关键信息，就可以获得预期满意的回答。这些示例可以硬编码，但如果动态选择，会更强大。Langchain 提供了少样本提示模板接受用户输入，然后返回包含示例列表的提示。

在这篇文章中，我们将详细探讨如何通过调整和增强提示，特别是加入一些具体的例子，让模型通过学习这些例子来提升自身的输出质量。你会惊讶地发现，这种微小的调整会对模型输出的结果产生巨大的影响。

首先，我们需要明白一点，这与我们之前所做的工作并无太大区别，其核心仍然是制作一个优秀的提示模板。现在，让我们通过一个具体的例子来理解这个过程。

假设我们现在的任务是让模型进行反义词接龙。在这个任务中，我们会给模型一个词，然后期望模型返回这个词的反义词。因此，我们需要提供一些示例，例如 "happy" 对应的反义词是 "sad"，"tall" 的反义词是 "short"，以此类推。然后，我们通过LangChain来设置我们的提示模板。

首先，我们会设置一个前缀，这样可以方便我们逐步构建提示的各个部分，以确保它们能完整地结合在一起。然后，我们会为模型设置一些标准的示例，以帮助模型理解任务需求。接下来，我们会设置一个Few Shot提示模板，然后在这里传入我们的示例。我们还会为此设置一个前缀和一个后缀，这样可以帮助模型更好地理解任务。

然后，我们运行代码，看看模型能否正确地生成我们期望的结果。例如，如果我们输入"big"，模型就应该返回"small"。这就是我们期望看到的反义词。

实际上，我们并没有看到整个提示，因为在大多数情况下，我们并不希望向用户展示完整的提示。因此，这就是使用提示模板制作提示的一种简单方法。

在这个过程中，标准提示模板和Few Shot提示模板都发挥了重要的作用。要注意的是，Few Shot提示模板的关键在于示例，因此你可以在这里使用一系列示例。这个示例只需要展示输入是什么，以及你期望的输出是什么。

我们通过下面代码，创建一个包含几个示例的少样本提示模板,来解释 FewShotPromptTemplate 的作用。

```
pip install openai langchain
```


导入 PromptTemplate, FewShotPromptTemplate 对象

```
from langchain.prompts.few_shot import FewShotPromptTemplate
from langchain.prompts.prompt import PromptTemplate
```

创建一个包含几个示例的列表

```
examples = [
    {"word": "happy", "antonym": "sad"},
    {"word": "tall", "antonym": "short"},
]
```

实例化 PromptTemplate 对象

```
example_prompt_format = """Word: {word}
Antonym: {antonym}
"""
example_prompt = PromptTemplate(input_variables=["word","antonym"], template=example_prompt_format)

print(example_prompt.format(**examples[0]))
```

实例化 FewShotPromptTemplate 对象

我们创建 FewShotPromptTemplate 对象，传入示例、示例格式化器、前缀、命令和后缀，这些都在指导 LLM 的输出。

此外，我们还可以提供输入变量 examples, example_prompt 和分隔符 example_separator="\n"，用于将示例与前缀 prefix 和后缀 suffix 分开。

```
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt, # 上一步实例化PromptTemplate对象
    prefix="Give the antonym of every input\n",
    suffix="Word: {input}\nAntonym: ",
    input_variables=["input"],
    example_separator="\n",
)
```

我们可以生成一个提示，它看起来像这样。

```
print(few_shot_prompt.format(input="big"))

Give the antonym of every input

Word: happy
Antonym: sad

Word: tall
Antonym: short

Word: big
Antonym: 
```

FewShotPromptTemplate 是一种非常有用的范例，可以控制 LLMs 的输出并引导其响应。

在实际的应用开发中,我们的示例相当复杂, 现实是我们在提示中还要加入大量的历史聊天信息,可是大型语言模型可以传递的标记数量是有限的，大多数模型最多可以传递1024到16000个标记。

Langchain 提供了控制提示长度的方法, 有兴趣的读者可以在官方文档中查看 LengthBasedExampleSelector 和 SemanticSimilarityExampleSelector 两种高阶的示例选择器, Langchain 还支持自定义示例选择器, 自己动手做一个示例选择器也是个不错的选择。