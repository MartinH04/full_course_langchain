# 2.2.2 示例提示模板 (FewShotPromptTemplate)

Prompts 中包含示例，大大提高模型的输出质量。

FewShotPromptTemplate 模板格式化的 Prompts 已经被证明是很有用的。通常用户只要输入关键信息，就可以获得预期满意的回答。这些示例可以硬编码，但如果动态选择，会更强大。示例提示模板接受用户输入，然后返回要使用的示例列表。

我们通过快速入门的代码，创建一个包含几个示例的少样本提示模板,来解释 FewShotPromptTemplate 的作用。


## 快速入门

### 导入库

```
pip install openai langchain
```


导入 PromptTemplate, FewShotPromptTemplate 对象

```
from langchain.prompts.few_shot import FewShotPromptTemplate
from langchain.prompts.prompt import PromptTemplate
```

创建一个包含几个示例的列表

```
examples = [
    {"word": "happy", "antonym": "sad"},
    {"word": "tall", "antonym": "short"},
]
```
### 实例化基类 PromptTemplate 对象

```
example_prompt_format = """Word: {word}
Antonym: {antonym}
"""
example_prompt = PromptTemplate(input_variables=["word","antonym"], template=example_prompt_format)

print(example_prompt.format(**examples[0]))
```

### 实例化 FewShotPromptTemplate 对象

我们创建 FewShotPromptTemplate 对象，传入示例、示例格式化器、前缀、命令和后缀，这些都在指导 LLM 的输出。

此外，我们还可以提供输入变量 examples, example_prompt 和分隔符 example_separator="\n"，用于将示例与前缀 prefix 和后缀 suffix 分开。

```
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt, # 上一步实例化PromptTemplate对象
    prefix="Give the antonym of every input\n",
    suffix="Word: {input}\nAntonym: ",
    input_variables=["input"],
    example_separator="\n",
)
```

我们可以生成一个提示，它看起来像这样。

```
print(few_shot_prompt.format(input="big"))

Give the antonym of every input

Word: happy
Antonym: sad

Word: tall
Antonym: short

Word: big
Antonym: 
```


FewShotPromptTemplate 是一种非常有用的范例，可以控制 LLMs 的输出并引导其响应。

在实际的应用开发中,我们的示例相当复杂, 现实是我们在提示中还要加入大量的历史聊天信息,可是大型语言模型可以传递的标记数量是有限的，大多数模型最多可以传递1024到16000个标记。

Langchain 提供了控制提示长度的方法, 有兴趣的读者可以在官方文档中查看 LengthBasedExampleSelector 和 SemanticSimilarityExampleSelector 两种高阶的示例选择器, Langchain 还支持自定义示例选择器, 自己动手做一个吧! 