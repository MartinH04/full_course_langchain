# 2.1.3 文本嵌入模型 (Text Embedding Models)

如果我们想要构建像聊天机器人之类的语言模型应用，或者使用搜索或外部数据的东西，跟真实的数据连接起来，仅仅一个大型语言模型是不够的。

一个很好的例子是如果我们想要大模型读取大型文档 《红楼梦》，并且询问关于这本书的一切问题。 

如果文档很大，对话很长，大模型该如何处理？

我们可能需要对进行总结或找到其他方法，因为大型语言模型可以传递的标记数量是有限的，大多数模型最多可以传递1024到16K个标记，一些新模型可以传递更多。


模型在高层次上有两种不同类型的模型：语言模型（language models）和文本嵌入模型（text embedding models）。嵌入模型将文本转换为数字数组，然后我们可以将文本视为向量空间。


## 嵌入模型的原理


![](https://pic3.zhimg.com/80/v2-df6b821706891153068f5ccc4fab7afa_1440w.jpeg)

在上面这个图像中，我们可以看到在一个二维空间中，“man”是“king”，“woman”是“queen”，它们代表不同的事物，但我们可以看到一种模式。

们可以在向量空间中寻找最相似的文本片段，实现语义搜索。

例如，OpenAI 的文本嵌入模型可以精确地嵌入大段文本，具体而言，8100 个标记，根据它们的词对标记比例 0.75，大约可以处理 6143 个单词。它输出 1536 维的向量。

我们可以使用 LangChain 与多个嵌入提供者进行接口交互，例如 OpenAI 和 Cohere 的 API，但我们也可以通过使用 Hugging Faces 的开源嵌入在本地运行，以达到 免费和数据隐私 的目的。

现在，您可以使用仅 4 行代码在自己的计算机上创建自己的嵌入。但是，维度数量可能会有所不同，嵌入的质量可能会较低，这可能会导致检索不太准确。


### 安装和设置密钥

我们需要安装 Langchain Python 包：

```bash
pip install openai langchain
```

### 使用 Text Embedding Models 的最简单方法

导入 OpenAIEmbeddings：

```python
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(openai_api_key = "YOUR_OPENAI_API_TOKEN")
result = embeddings.embed_query("This is an apple.")

```

打印 result ，我们就可以看到 "This is an apple." 这句话的向量空间表达数组。

```
[0.012008527293801308,
 -0.001835253438912332,
 0.00145026296377182,
 -0.0030227703973650932,
 -0.005661344155669212,
 0.005086636636406183,...]
```

打印出的数字并不能直接反映这些词在向量空间中的位置，但如果你对此感兴趣，可以访问OpenAI的官方网站，那里有许多关于词嵌入（embedding）可视化的实践场所（playground）供你探索和学习。