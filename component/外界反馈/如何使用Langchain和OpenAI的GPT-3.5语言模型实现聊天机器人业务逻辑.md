如何使用Langchain和OpenAI的GPT-3.5语言模型实现聊天机器人业务逻辑。


**2 背景**  

作为一个例子，图1说明了一个设计为工作市场的LLM集成网络应用程序。它提供了一个聊天机器人，旨在帮助发现由其他用户发布的网页应用程序除了包括客户端浏览器、Web服务器应用逻辑和数据库等传统组件外，这个应用程序的架构还引入了两个额外的组件：一个LLM集成中间件，如Langchain，和一个语言模型(LLM)。中间件提供一个API，业务逻辑控制器调用它以启用聊天机器人功能。要使用的具体LLM是基于配置决定的。当用户提交一个问题时，聊天机器人控制器代码调用Langchain API，它在内部与LLM交互来解释问题并生成一个辅助SQL查询(步骤1)。随后，Langchain在数据库上执行SQL查询(步骤2)，然后再次询问LLM，现在使用SQL查询的结果，为用户生成最终答案。在这个例子中，数据库有两个表 - users和job_postings，分别填充了关于两个用户John和Alice的信息，以及由John发布的三个工作职位，这些职位被分配给了用户ID 1。网页显示了Alice（用户ID 2）和聊天机器人之间的简单对话，Alice询问伦敦薪酬最高的五个工作，聊天机器人利用数据库中的信息生成了适当的回应。

清单1展示了如何使用Langchain和OpenAI的GPT-3.5语言模型实现聊天机器人业务逻辑。这段Python代码首先创建了ChatOpenAI类的实例(代表GPT-3.5 LLM的包装器)。4-9行在路径‘/chatbot’上建立了一个POST端点，利用FastAPI库[24]。当用户向聊天机器人助手提交一个问题时，chatbot函数就会被触发，请求对象在其输入属性中封装了用户的问题。为了处理请求，代码建立了与数据库的连接(第6行)，并实例化了一个SQLDatabaseChain对象，它实现了一个Langchain的内置预配置聊天机器人，可以与SQL数据库交互(第7行)。在第8行处理用户的问题：调用SQLDatabaseChain对象，接收提出的问题作为输入，并返回LLM生成的响应。这个响应持有对用户问题的答案，并在第9行发回给用户。

Langchain执行步骤。为了检查SQL注入攻击的潜在风险，我们需要理解Langchain如何在内部处理用户的问题。图2帮助我们解剖其涉及LLM和数据库的内部协议。直观地说，语言模型将尝试按照Langchain以LLM提示的形式提供的指示生成文本。

在第一步，Langchain根据清单2中显示的默认提示模板构建这个LLM提示，将预定义的令牌(封装在括号中)替换为特定的值：用户的输入问题（input）、数据库模式（table_info）和数据库结果的限制（top_k）。生成的LLM提示将引导整个处理过程。从第1行到第5行，Langchain指示LLM按照以下格式生成文本：

1 你是一个PostgreSQL专家。给定一个输入问题，首先创建一个
↩→ 语法正确的PostgreSQL查询来运行，然后查看查询的
↩→ 结果，并返回对输入问题的答案。
2 除非用户在问题中明确指定要获得的特定数量的示例，
↩→ 否则使用LIMIT子句按照PostgreSQL查询最多{top_k}的结果。
↩→ 你可以对结果进行排序，以返回数据库中的最有信息的数据。
3 绝不要查询表中的所有列。你只能查询回答问题所需的
↩→ 列。用双引号(")将每个列名包起来，表示它们是界定的标识符。
4 注意只使用你在下面的表中可以看到的列名。小心不要查询
↩→ 不存在的列。此外，注意哪一列在哪个表中。
5 如果问题涉及“今天”，请注意使用CURRENT_DATE函数获取当前日期。
6
7 使用以下格式：
8
9 问题：这里的问题
10 SQL查询：要运行的SQL查询
11 SQL结果：SQL查询的结果
12 答案：这里的最终答案
13
14 只使用以下表格：
15
16 {table_info}
17
18 问题：{input}


LLM要模拟PostgreSQL专家并为输入问题生成有意义的SQL查询。从数据库连接中检索的数据库模式使LLM能够生成语法正确的SQL查询(行14-16)。重要的是，在第7行和第12行之间，提示告诉LLM它应该遵循生成文本的“脚本”，这样，如果Langchain向LLM发送一个以问题结束的提示(第18行)，LLM必须生成剩下的文本，即完成字段SQLQuery、SQLResult和Answer。

因此，在替换默认提示模板的令牌后，LLM提示字符串以句子结束：“问题：伦敦薪酬最高的五个工作是什么？”。正是这个LLM提示字符串，Langchain在第1步中发送给LLM。在正常情况下，LLM会一次性填写所有剩余的字段。然而，Langchain告诉LLM它应该在尝试生成关键字SQLResult时停止生成文本，否则，LLM只会发明任意的SQL查询结果，而不是使用来自数据库的信息。因此，LLM只响应一个包含LLM自动生成的SQL查询的SQLQuery字段的完成。此查询在清单3中的执行步骤中可见，行1-5。

在第2步，Langchain从LLM给出的响应中提取SQL查询，并在数据库上执行它。使用数据库返回的结果，Langchain将SQLResult字符串和SQL查询的序列化结果添加到LLM提示中(参见清单3中的第6行)，并向LLM发出第二个请求(第3步)。在这一步，LLM看到只需要完成Answer字段，现在它可以利用嵌入到提示中的数据库SQL查询的实际结果来为用户生成最终的响应。此响应在清单3中，行7-12可见。此列表表示用户输入处理的中间步骤，其中红色部分是LLM填写的信息，蓝色部分是Langchain添加的信息，作为在数据库上运行SQL查询的结果。

SQL chain vs. SQL agent。清单1中呈现的聊天机器人实现使用了一个预训练的聊天机器人组件，该组件在Langchain中被称为SQL chain，它实现了图2中描绘的执行协议，允许在回答用户问题的过程中在数据库上执行一个SQL查询。除了SQL chain，Langchain还有另一种类型的预配置聊天机器人引擎，允许执行多个SQL查询，从而回答更复杂的问题。这种类型的聊天机器人被命名为SQL agent，可以通过使用SQLDatabaseAgent组件代替SQLDatabaseChain来使用。