

# 7.2 实现 AutoGPT


Auto-GPT 是一个开源的实验性应用程序，它展示了 GPT-4 语言模型的能力。这个由 GPT-4 驱动的程序，通过串联起 LLM（大型语言模型）的 "思考"，以实现你设定的任何目标。作为 GPT-4 全自主运行的首批示例之一，AutoGPT 拓宽了人工智能可能达到的边界。

想象一下，你正在编写一个复杂的报告，这需要从多个方面进行深入研究。这时候，你可以设定一个目标，让 Auto-GPT 帮你完成这项任务。你会看到 Auto-GPT 如何通过串联起大型语言模型的 "思考"，自动收集相关的信息，形成一个结构化的报告，这就如同你的个人助手在帮你分担 "工作的压力"。

在所有这些中，Auto-GPT 所展示的能力，无疑推动了人工智能的可能性。例如，它可以自动写作文章，分析大量数据，甚至参与到复杂的决策过程中，这些都是我们以前认为只有人类才能做的事情。正因为如此，Auto-GPT 无疑正在挑战我们对于人工智能的想象。

### 7.2.1 使用 LangChain 实现 AutoGPT

这一节将介绍如何使用 LangChain 的基本组件（如大型语言模型，提示模板，向量存储，嵌入，工具等）来实现一个 AutoGPT 模型。AutoGPT 是一个自动化的大型语言模型项目，它可以进行多种任务，包括文件读取、写入和搜索等。

安装库。

```bash
pip -q install  openai tiktoken
pip install git+https://github.com/hwchase17/langchain
```

设置密钥。

```
import os

os.environ["OPENAI_API_KEY"] = ""
```
我们来设置一些工具，这包括搜索工具、写文件工具和读文件工具，这些都是为了让 AutoGPT 能够更好地完成任务。

```
from langchain.utilities import SerpAPIWrapper
from langchain.agents import Tool
from langchain.tools.file_management.write import WriteFileTool
from langchain.tools.file_management.read import ReadFileTool

search = SerpAPIWrapper()
tools = [
    Tool(
        name="search",
        func=search.run,
        description="useful for when you need to answer questions about current events. You should ask targeted questions",
    ),
    WriteFileTool(),
    ReadFileTool(),
]
```

设置内存，这是用于存储模型在执行任务过程中的中间步骤。这对于理解模型的工作过程和改进模型的性能都非常重要。

```
from langchain.vectorstores import FAISS
from langchain.docstore import InMemoryDocstore
from langchain.embeddings import OpenAIEmbeddings
```
我们使用 OpenAI 的嵌入模型, 向量库使用 FAISS。

```
# Define your embedding model
embeddings_model = OpenAIEmbeddings()
# Initialize the vectorstore as empty
import faiss

embedding_size = 1536
index = faiss.IndexFlatL2(embedding_size)
vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})
```

在设置好工具和内存后，初始化模型和 AutoGPT。我们选择的模型是 ChatOpenAI，这是一个专为对话设计的大语言模型。

```
from langchain.experimental import AutoGPT
from langchain.chat_models import ChatOpenAI
```

```
agent = AutoGPT.from_llm_and_tools(
    ai_name="Tom",
    ai_role="Assistant",
    tools=tools,
    llm=ChatOpenAI(temperature=0),
    memory=vectorstore.as_retriever(),
)
# Set verbose to be true
agent.chain.verbose = True
```

接下来，运行一个示例，让 AutoGPT 为旧金山编写一份天气报告。这展示了 AutoGPT 在实际应用中的能力。

```
agent.run(["write a weather report for SF today"])
```

### 7.2.2 设置聊天历史记录的内存

最后，设置聊天历史记录的内存。这是除了用于存储模型中间步骤的内存之外的另一种内存。这种内存默认使用'ChatMessageHistory'，但可以改变。当你希望使用不同类型的内存，例如'FileChatHistoryMemory'时，这将非常有用。

```
from langchain.memory.chat_message_histories import FileChatMessageHistory

agent = AutoGPT.from_llm_and_tools(
    ai_name="Tom",
    ai_role="Assistant",
    tools=tools,
    llm=ChatOpenAI(temperature=0),
    memory=vectorstore.as_retriever(),
    chat_history_memory=FileChatMessageHistory("chat_history.txt"),
)
```
我们运行询问上海现在的天气如何, 测试这种方式是否生效。

```
agent.run(["write a weather report for Shanghai today"])
```
我的文件夹里多了 weather_report.txt 和 chat_history.txt 两个文件
```
{
  "thoughts": {
    "text": "Since I have completed the task of writing a weather report for San Francisco, I can now move on to the next task. One possible task could be to write a weather report for Shanghai today. This will allow me to provide the user with up-to-date weather information for Shanghai.",
    "reasoning": "Writing a weather report is a simple and straightforward task that I can easily accomplish. It will provide useful information to the user and help them plan their activities accordingly.",
    "plan": "- Use the 'search' command to search for the weather in Shanghai today.\n- Analyze the search results and extract the relevant information.\n- Write a weather report for Shanghai today.",
    "criticism": "I need to ensure that I accurately extract the weather information from the search results and provide a clear and concise weather report to the user.",
    "speak": "I will search for the weather in Shanghai today and provide you with a weather report."
  },
  "command": {
    "name": "search",
    "args": {
      "tool_input": "weather in Shanghai today"
    }
  }
}
```
这就是如何使用 LangChain 的基本组件来实现 AutoGPT。