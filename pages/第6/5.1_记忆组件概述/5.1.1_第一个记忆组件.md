### 5.1.1 第一个记忆组件

通过这个例子，我们可以用代码演示如何实例化一个记忆组件，以及如何使用记忆组件的保存和加载方法来管理聊天记录。这种使用记忆组件的方式对于所有的记忆组件都是通用的，只是在具体的实现细节上可能会有所不同。

首先，我们需要引入 `ConversationTokenBufferMemory` 类，并创建一个 `OpenAI` 类的实例作为其参数。 `ConversationTokenBufferMemory` 是一个记忆组件，它将最近的交互信息保存在内存中，并使用令牌长度而不是交互次数来决定何时清除交互信息。

```python
from langchain.memory import ConversationTokenBufferMemory
from langchain.llms import OpenAI
openai_api_key = "填入你的OpenAI密钥"
llm = OpenAI(openai_api_key=openai_api_key)
memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=1000,memory_key="session_chat")
```

在上面的代码中，我们首先创建了一个 `OpenAI` 实例 `llm` 类型的模型包装器，然后用这个实例和一个 `max_token_limit` 参数来创建 `ConversationTokenBufferMemory` 的实例 `memory`。 `max_token_limit` 参数用于设置记忆组件可以保存的 Max Token 数量, 数字设置过于小的话，可能最后打印的对象是空字符串，可以手动设置 10，再设置 100 查看效果。`memory_key` 参数用于设置记忆组件存储对象的键名，默认是 `history`，这里我们设置为 `session_chat`。

接下来，我们可以使用 `save_context` 方法来将聊天记录保存到记忆组件中。每次调用 `save_context`，都会将一次交互（包括用户的输入和大语言模型的输出）添加到记忆组件的缓冲区中。

```python
memory.save_context({"input": "你好！我是李特丽，这是人类的第一个消息"}, {"output": "你好！我是AI助理的第一个消息"})
memory.save_context({"input": "今天心情怎么样"}, {"output": "我很开心认识你"})
```

在上面的代码中，我们先后保存了两次交互记录。第一次交互中，用户的输入是 "你好！我是李特丽，这是人类的第一个消息"；第二次交互中，用户的输入是 "今天心情怎么样"，大语言模型的输出是 "我很开心认识你"。

```python
memory.load_memory_variables({})
```

最后，我们可以使用 `load_memory_variables` 方法来加载记忆组件中的聊天记录。这个方法会返回一个字典，其中包含了记忆组件当前保存的所有聊天记录。
```
{'session_chat': 'Human: 你好！我是李特丽，这是人类的第一个消息\nAI: 你好！我是AI助理的第一个消息\nHuman: 今天心情怎么样\nAI: 我很开心认识你'}
```

以上就是如何使用 `ConversationTokenBufferMemory` 记忆组件的示例。

