# 回调处理器

### 7.1.1 回调处理器的用途

你是否有过这样的经历：在开发一个复杂的链或者代理时，你需要在每个链的各个阶段都实时监控其状态，以便在出现问题时能迅速定位和解决。例如，你正在开发一个复杂的链，这个模型需要在给定的输入下，依次通过多个处理链条生成预期的输出。在这个过程中，模型每处理一个输入，都会消耗一定的令牌(token)。这时，希望能在执行过程中监控令牌消耗是很常见的业务需求, 你需要在各个阶段监控状态，出现问题时，快速定位解决。

没有合适的工具和方法，任务难以完成。可能要在链组件代码中添加监控令牌消耗的代码，过程繁琐，导致代码混乱难以维护。

LangChain 的回调处理器系统提供帮助。使用或自定义回调处理器，自动监控链条执行中的令牌消耗。令牌消耗超预期，处理器记录相关信息，可能触发其他操作，如发送警报或自动调整链的参数。方便有效管理模型和令牌消耗，避免大量的手动监控代码。

实际开发中，我们还想要记录模型输出到文件或数据库，数据分析和使用；或追踪模型运行时间，优化模型性能。没有合适的工具和方法，任务困难繁琐。

大语言模型开发中，回调处理器成为重要设计模式, 主要为我们的程序异常处理做了封装。在数据处理、网络请求、用户界面反馈，日志记录等场景下，回调处理器都能发挥作用。使用或自定义回调处理器，完成各种任务。例如，使用 FileCallbackHandler 记录模型输出到文件，或使用 TimeCallbackHandler 追踪模型运行时间。预设的回调处理器不满足需求，基于 BaseCallbackHandler 创建自定义的回调处理器也是可行的。

### 7.1.2 回调处理器的代码演示

例如，以下是一个使用 LangChain 回调处理器的代码片段：

```python
from langchain.callbacks import get_openai_callback
from langchain.llms import OpenAI

llm = OpenAI(temperature=0)
with get_openai_callback() as cb:
    llm("What is the square root of 4?")

total_tokens = cb.total_tokens
assert total_tokens > 0

# ...
```

这段代码中，首先创建了一个 OpenAI 模型实例，并通过 `get_openai_callback()` 函数获取一个回调处理器。然后，通过回调处理器，我们可以方便地获取模型执行的结果。

#### 异步的任务

但 LangChain 的回调处理器不仅可以处理同步的任务，也可以处理异步的任务，这大大增加了其灵活性。例如，以下的代码展示了如何使用回调处理器处理并发的任务：

```python
# ...

with get_openai_callback() as cb:
    await asyncio.gather(
        *[llm.agenerate(["What is the square root of 4?"]) for _ in range(3)]
    )

assert cb.total_tokens == total_tokens * 3

# ...
```

在这段代码中，我们创建了 3 个并发的任务，并使用同一个回调处理器来处理它们的结果。即使任务是并发的，回调处理器也能正确地处理每个任务的结果，并将它们汇总起来。

这就是 LangChain 回调处理器强大的功能。

